{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esta notebook es creada para hacer pruebas con el procesamiento de la informacion de los documentos csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _para limpiar los documentos extraidos del pdf_\n",
    "    ->> obtener una lista de todas las materias con sus nrc y la carrera en la que se ofertan\n",
    "    --- limpiar la lista de materias (toLower)\n",
    "    --- sustituir los nombres de materias por los correctos\n",
    "    ---reemplazar los NAN donde se genera esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Materia</th>\n",
       "      <th>Clave</th>\n",
       "      <th>Secc</th>\n",
       "      <th>NRC</th>\n",
       "      <th>Dias</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Salon</th>\n",
       "      <th>Profesor</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Inteligencia Artificial</td>\n",
       "      <td>CCOM 262</td>\n",
       "      <td>OO1</td>\n",
       "      <td>29089</td>\n",
       "      <td>AJ</td>\n",
       "      <td>0900-1059</td>\n",
       "      <td>1EMA4/409</td>\n",
       "      <td>ZACARIAS - FLORES FERNANDO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Inteligencia Artificial</td>\n",
       "      <td>CCOM 262</td>\n",
       "      <td>OO1</td>\n",
       "      <td>29089</td>\n",
       "      <td>L</td>\n",
       "      <td>1000-1059</td>\n",
       "      <td>1EMA4/409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Arqu. Funcional de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZACARIAS - FLORES FERNANDO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Computadora</td>\n",
       "      <td>IDCO 200</td>\n",
       "      <td>OO1</td>\n",
       "      <td>29093</td>\n",
       "      <td>L</td>\n",
       "      <td>1300-1359</td>\n",
       "      <td>1CCO5/201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Arqu. Funcional de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SANCHEZ - GALVEZ MARIA EUGENIA N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Computadora</td>\n",
       "      <td>IDCO 200</td>\n",
       "      <td>OO1</td>\n",
       "      <td>29093</td>\n",
       "      <td>M</td>\n",
       "      <td>1300-1459</td>\n",
       "      <td>1CCO3/309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Materia     Clave Secc    NRC Dias       Hora      Salon  \\\n",
       "16  Inteligencia Artificial  CCOM 262  OO1  29089   AJ  0900-1059  1EMA4/409   \n",
       "17  Inteligencia Artificial  CCOM 262  OO1  29089    L  1000-1059  1EMA4/409   \n",
       "18       Arqu. Funcional de       NaN  NaN     -1  NaN        NaN        NaN   \n",
       "19              Computadora  IDCO 200  OO1  29093    L  1300-1359  1CCO5/201   \n",
       "20       Arqu. Funcional de       NaN  NaN     -1  NaN        NaN        NaN   \n",
       "21              Computadora  IDCO 200  OO1  29093    M  1300-1459  1CCO3/309   \n",
       "\n",
       "                            Profesor  Doc  \n",
       "16        ZACARIAS - FLORES FERNANDO    0  \n",
       "17                               NaN    0  \n",
       "18        ZACARIAS - FLORES FERNANDO    0  \n",
       "19                               NaN    0  \n",
       "20  SANCHEZ - GALVEZ MARIA EUGENIA N    0  \n",
       "21                               NaN    0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###celda de erorres TODO\n",
    "data[0][16:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recibe un directorio\n",
    "#retorna todos los documentos de ese directorio\n",
    "def getDocsinDir(directory):\n",
    "    return list(map(lambda x: directory+x,os.listdir(directory)))\n",
    "#recibe una lista de nombres de documentos\n",
    "#retorna un lista de dataFrames\n",
    "def getCSVs(docs):\n",
    "    data=[]\n",
    "    for x in docs:\n",
    "        data.append(pd.read_csv(x))\n",
    "    return data\n",
    "#recibe un panda.Dataframes\n",
    "    #elimina todos los elementos nulos y ajusta los nombres de materias y profesores\n",
    "#retorna el mismo Dataframe  \n",
    "def cleanData(data):    \n",
    "        data = data[data['Materia'].notna()]\n",
    "        data['NRC']=data['NRC'].replace(to_replace=np.nan,value=-1)\n",
    "        #data[2].dropna(inplace=True)\n",
    "        data.reset_index(drop=True,inplace=True)\n",
    "        bad=data.loc[lambda y: y.Materia=='Materia']\n",
    "        #print(bad)\n",
    "        badIndexes=bad.index.to_list()\n",
    "        #print(badIndexes)\n",
    "        data.reset_index(drop=True,inplace=True)\n",
    "        data=data.drop(badIndexes)\n",
    "        \n",
    "        return data\n",
    "#recibe el arreglo de dataframes \n",
    "##Recupera todas las materias con sus respectivos nrc\n",
    "## devuelve un dataFrame de todas la materias con su nrc\n",
    "def getCleanMaterias(data):\n",
    "    \n",
    "    materias=data[0].Materia.tolist()\n",
    "    nrcs=data[0].NRC.tolist()\n",
    "    numOfDoc=data[0].Doc.tolist()\n",
    "    \n",
    "    for x in range(len(data)-1):\n",
    "        materias.extend(data[x+1].Materia.tolist())\n",
    "        nrcs.extend(data[x+1].NRC.tolist())\n",
    "        numOfDoc.extend(data[x+1].Doc.tolist())\n",
    "        \n",
    "    antesMat=\"\"\n",
    "    antesNrc=0\n",
    "    realMaterias=[]\n",
    "    for m,n,d in zip(materias,nrcs,numOfDoc):\n",
    "        ahoraMat=m\n",
    "        ahoraNrc=n\n",
    "        if(antesNrc==-1):\n",
    "            #print('aqui----'+antesMat+' '+m,n,type(n))\n",
    "            helpDic={0:antesMat+' '+m,1:n,2:str(d)}\n",
    "            realMaterias.append(helpDic)\n",
    "        elif(ahoraNrc!=-1):\n",
    "            helpDic={0:m,1:n,2:str(d)}\n",
    "            #print(m,n,type(n))\n",
    "            realMaterias.append(helpDic)\n",
    "        antesNrc=n\n",
    "        antesMat=m\n",
    "    p=pd.DataFrame(realMaterias)\n",
    "    p=p.rename(columns={0:'Materia',1:'NRC',2:'Doc'})\n",
    "    p=p.drop_duplicates()\n",
    "    return p\n",
    "\n",
    "def get_materias(data):\n",
    "    materias=data.Materia.tolist()\n",
    "    nrcs=data.NRC.tolist()\n",
    "    \n",
    "    antesMat=\"\"\n",
    "    antesNrc=0\n",
    "    realMaterias=[]\n",
    "    for m,n in zip(materias,nrcs):\n",
    "        ahoraMat=m\n",
    "        ahoraNrc=n\n",
    "        if(antesNrc==-1):\n",
    "            #print('aqui----'+antesMat+' '+m,n,type(n))\n",
    "            helpDic={0:antesMat+' '+m,1:n}\n",
    "            realMaterias.append(helpDic)\n",
    "        elif(ahoraNrc!=-1):\n",
    "            helpDic={0:m,1:n}\n",
    "            #print(m,n,type(n))\n",
    "            realMaterias.append(helpDic)\n",
    "        antesNrc=n\n",
    "        antesMat=m\n",
    "    p=pd.DataFrame(realMaterias)\n",
    "    p=p.rename(columns={0:'Materia',1:'NRC'})\n",
    "    p=p.drop_duplicates()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=getDocsinDir(\"app/filesCSV/\")\n",
    "data=getCSVs(docs)\n",
    "for x in range(len(data)):\n",
    "        data[x]=cleanData(data[x])\n",
    "        p=[x]*len(data[x])\n",
    "        data[x]['Doc']=p ##genera una columna que almacene a que numero de documento pertenece\n",
    "        \n",
    "Materias=getCleanMaterias(data)\n",
    "nombresMaterias=Materias.Materia.unique().tolist()\n",
    "gg=get_materias(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_integrity(gg,data):\n",
    "    conta=0\n",
    "    for x in gg[\"NRC\"]:\n",
    "        encontrado= False\n",
    "        for y in data[\"NRC\"]:\n",
    "            if x == y :\n",
    "                encontrado=True\n",
    "                pass\n",
    "\n",
    "        if not encontrado:\n",
    "            print(\"no encontrado {}\".format(x))\n",
    "        else:\n",
    "            conta+=1\n",
    "    return conta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.to_json(\"dd.json\",orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Materia</th>\n",
       "      <th>NRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lengua Extranjera III</td>\n",
       "      <td>20021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lengua Extranjera IV</td>\n",
       "      <td>20022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lengua Extranjera IV</td>\n",
       "      <td>20022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analisis y Diseno de Algoritm</td>\n",
       "      <td>29066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analisis y Diseno de Algoritm</td>\n",
       "      <td>29066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analisis y Diseno de Algoritm</td>\n",
       "      <td>29070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analisis y Diseno de Algoritm</td>\n",
       "      <td>29070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Microprocesadores</td>\n",
       "      <td>29072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Microprocesadores</td>\n",
       "      <td>29072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microprocesadores</td>\n",
       "      <td>29072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Materia    NRC\n",
       "0          Lengua Extranjera III  20021\n",
       "1           Lengua Extranjera IV  20022\n",
       "2           Lengua Extranjera IV  20022\n",
       "3  Analisis y Diseno de Algoritm  29066\n",
       "4  Analisis y Diseno de Algoritm  29066\n",
       "5  Analisis y Diseno de Algoritm  29070\n",
       "6  Analisis y Diseno de Algoritm  29070\n",
       "7              Microprocesadores  29072\n",
       "8              Microprocesadores  29072\n",
       "9              Microprocesadores  29072"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][[\"Materia\",\"NRC\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Materia</th>\n",
       "      <th>NRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lengua Extranjera III</td>\n",
       "      <td>20021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lengua Extranjera IV</td>\n",
       "      <td>20022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analisis y Diseno de Algoritm</td>\n",
       "      <td>29066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analisis y Diseno de Algoritm</td>\n",
       "      <td>29070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Microprocesadores</td>\n",
       "      <td>29072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Programacion Distribuida</td>\n",
       "      <td>29074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Recuperacion de Informacion</td>\n",
       "      <td>29078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Inteligencia Artificial</td>\n",
       "      <td>29089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Arqu. Funcional de Computadora</td>\n",
       "      <td>29093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Interaccion Humano Computadora</td>\n",
       "      <td>29105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Computabilidad</td>\n",
       "      <td>29109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Proyectos I + D I</td>\n",
       "      <td>29112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Proyectos I + D I</td>\n",
       "      <td>29114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Proyectos I + D I</td>\n",
       "      <td>29115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Progra. Concurrente y Paralela</td>\n",
       "      <td>29163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ingenieria de Software</td>\n",
       "      <td>29165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sistemas Operativos II</td>\n",
       "      <td>29169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Administracion de Proyectos</td>\n",
       "      <td>29172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Administracion de Proyectos</td>\n",
       "      <td>29177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Animacion por Computadora</td>\n",
       "      <td>29183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Animacion por Computadora</td>\n",
       "      <td>29185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Animacion por Computadora</td>\n",
       "      <td>29186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Aplicaciones Multimedia</td>\n",
       "      <td>29187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Aplicaciones Multimedia</td>\n",
       "      <td>29194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Aplicaciones Multimedia</td>\n",
       "      <td>29197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Aplicaciones Web</td>\n",
       "      <td>29200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Aplicaciones Web</td>\n",
       "      <td>29201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Aplicaciones Web</td>\n",
       "      <td>29202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Aplicaciones Web</td>\n",
       "      <td>29203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Procesam. Digital de Imagenes</td>\n",
       "      <td>29205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Procesam. Digital de Imagenes</td>\n",
       "      <td>29206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Procesam. Digital de Imagenes</td>\n",
       "      <td>29209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Mineria de Datos</td>\n",
       "      <td>29211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Ingenieria deSoftware Avanzada</td>\n",
       "      <td>29218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Bases de Datos Avanzadas</td>\n",
       "      <td>29220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Lengua Extranjera III</td>\n",
       "      <td>37568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Lengua Extranjera IV</td>\n",
       "      <td>37570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Proyectos I + D II</td>\n",
       "      <td>38027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Proyectos I + D II</td>\n",
       "      <td>38033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Proyectos I + D II</td>\n",
       "      <td>38040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Topicos Ing. en Computacion</td>\n",
       "      <td>40838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Materia    NRC\n",
       "0            Lengua Extranjera III  20021\n",
       "1             Lengua Extranjera IV  20022\n",
       "3    Analisis y Diseno de Algoritm  29066\n",
       "5    Analisis y Diseno de Algoritm  29070\n",
       "7                Microprocesadores  29072\n",
       "10        Programacion Distribuida  29074\n",
       "13     Recuperacion de Informacion  29078\n",
       "16         Inteligencia Artificial  29089\n",
       "18  Arqu. Funcional de Computadora  29093\n",
       "21  Interaccion Humano Computadora  29105\n",
       "24                  Computabilidad  29109\n",
       "26               Proyectos I + D I  29112\n",
       "27               Proyectos I + D I  29114\n",
       "29               Proyectos I + D I  29115\n",
       "31  Progra. Concurrente y Paralela  29163\n",
       "34          Ingenieria de Software  29165\n",
       "36          Sistemas Operativos II  29169\n",
       "39     Administracion de Proyectos  29172\n",
       "41     Administracion de Proyectos  29177\n",
       "43       Animacion por Computadora  29183\n",
       "46       Animacion por Computadora  29185\n",
       "49       Animacion por Computadora  29186\n",
       "52         Aplicaciones Multimedia  29187\n",
       "55         Aplicaciones Multimedia  29194\n",
       "58         Aplicaciones Multimedia  29197\n",
       "61                Aplicaciones Web  29200\n",
       "64                Aplicaciones Web  29201\n",
       "67                Aplicaciones Web  29202\n",
       "70                Aplicaciones Web  29203\n",
       "72   Procesam. Digital de Imagenes  29205\n",
       "75   Procesam. Digital de Imagenes  29206\n",
       "78   Procesam. Digital de Imagenes  29209\n",
       "81                Mineria de Datos  29211\n",
       "84  Ingenieria deSoftware Avanzada  29218\n",
       "86        Bases de Datos Avanzadas  29220\n",
       "89           Lengua Extranjera III  37568\n",
       "90            Lengua Extranjera IV  37570\n",
       "92              Proyectos I + D II  38027\n",
       "94              Proyectos I + D II  38033\n",
       "96              Proyectos I + D II  38040\n",
       "98     Topicos Ing. en Computacion  40838"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _para indexador de palabras de documento de texto:_\n",
    "        → retorna un diccionario con todas las palabras encontradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def simbologia\n",
    "#???? => es necesario?\n",
    "# [linea] ? [linea] => cual de las dos opciones es mejor?\n",
    "#DEFINIR CLASE Match\n",
    "#     class Match:\n",
    "#      numerodelinea=int\n",
    "#      ubicacion en la linea=[]  \n",
    "\n",
    "#para indexador de indice invertido\n",
    "    #leer todo el documento linea a linea\n",
    "    #limpiar el texto\n",
    "    #TOKENIZAR CADA PALABRA EN LA LINEA \n",
    "    #almacenar numero de palabras en la linea ????? (necesario si queremos calcular la pocision de la palabra relativa al doc)\n",
    "    #si la palabra NO esta en stop words y aun no esta en el diccionario:\n",
    "        #agregar la palabra al diccionario con su diccionario correspodiente\n",
    "        #guardar en su diccionario el numero de documento al que corresponde\n",
    "        #inicializar el primer elemnto de la lista (APARICIONES)=1 de la palabra en el diccionario del documento\n",
    "        #crear una nueva instancia match\n",
    "           #almacenar en que linea esta (NUM_LINEA)\n",
    "            #almacenar la ubicacion de la palabra  (relativo a la linea)\n",
    "                # almacenar que numero de palabra ocupa en la linea ? almacenar numero de caracter en el que inicia la palabra\n",
    "        #agregar la instancia de Match a la lista del diccionario de la palabra\n",
    "    #si la palabra ya esta en el diccionario\n",
    "        #incrementar por uno (APARICIONES)\n",
    "        #revisar el match.Linea anterior\n",
    "            #si es la misma linea en la que está\n",
    "                #actualizar la lista de apariciones\n",
    "            #sino\n",
    "                #crear una nueva instancia match\n",
    "                #agregar la instancia de Match a la lista del diccionario de la palabra\n",
    "        \n",
    "#estructura: lista de diccionarios t.q:\n",
    "\n",
    "#    {'token o palabra': {NUM_DOC:[APARICIONES,Match1,Match2],NUM_DOC:[APARICIONES,Match1,Match2]}}\n",
    "# [[,,,,][,,,,]] cada lista corrsponde a  un documento y la pocision de la lista almacena el numero de palabras en la linea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match:\n",
    "    def __init__(self,numeroLinea : int, ocurrencias: list):\n",
    "        self.linea=numeroLinea\n",
    "        self.ocurrencias=ocurrencias\n",
    "    def addOcurrencias(self, new:list):\n",
    "        for elem in new:\n",
    "            if elem not in self.ocurrencias:\n",
    "                self.ocurrencias.append(elem)\n",
    "    def getOcurrencias(self):\n",
    "        return self.ocurrencias\n",
    "    def getLinea(self):\n",
    "        return self.linea\n",
    "    def getNumOcurrencias(self):\n",
    "        return len(self.ocurrencias)\n",
    "\n",
    "#clase modificada para que retorne una lista en lugar del objeto\n",
    "class Match2():\n",
    "    def __init__(self,match:list):\n",
    "        self.linea=match[0]\n",
    "        self.ocurrencias=match[1:]\n",
    "    def getMatch(self):\n",
    "        return [self.linea,self.ocurrencias]\n",
    "    def addOcurrencias(self,new:list):\n",
    "        for elem in new:\n",
    "            if elem not in self.ocurrencias:\n",
    "                self.ocurrencias.append(elem)\n",
    "        return [self.linea,self.ocurrencias]\n",
    "    def getOcurrencias(self):\n",
    "        return self.ocurrencias\n",
    "    def getLinea(self):\n",
    "        return self.linea\n",
    "    def getNumOcurrencias(self,):\n",
    "        return len(self.ocurrencias)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ho4lá 5ño dfs   10921d aquíhool8    más'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "stopWords=set(stopwords.words('spanish'))\n",
    "stopWordsEngl=set(stopwords.words('english'))\n",
    "#recibe una cadena\n",
    "#retorna una cadena limpia\n",
    "def normal(string):\n",
    "    string=re.sub('_',' ',string)\n",
    "    string=re.sub(r'[^\\w\\s]+',' ',string) #elimina simbolos\n",
    "    string=re.sub(r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\",' ',string) ##elimina numeros solos\n",
    "    string=re.sub(r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\",' ',string) ##elimina numeros solos\n",
    "    string=string.lower()#↓↓ RETIRA DIACRITICOS MENOS ñ\n",
    "   #string = re.sub(r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\",r\"\\1\",normalize( \"NFD\",string),0,re.I)\n",
    "    #string = normalize( 'NFC', string)\n",
    "    return string\n",
    "\n",
    "normal('ho4lá 5ño 1988´.dfs_?¡¿ 2 10921d aquíHOOL8 7545 :2012. 1901. más') #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rutina para indexador\n",
    "# recibe una lista de nombres de documentos \n",
    "#retorna un diccionario (la estructura del indexador)\n",
    "headIndexer={}\n",
    "numeroPalabrasPorDoc=[]\n",
    "def makeIndex(docs:list):\n",
    "    numDoc=0\n",
    "    for x in docs:\n",
    "        numeroPalabrasPorDoc.append([])\n",
    "        tokens=[]\n",
    "        doc=open(x,encoding='utf8')\n",
    "        data=doc.readlines()\n",
    "        ##para cada linea en el documento\n",
    "        for i in range(len(data)):\n",
    "            data[i]=normal(data[i])\n",
    "            lineTokenized=word_tokenize(data[i])\n",
    "            numeroPalabrasPorDoc[numDoc].append(len(lineTokenized))\n",
    "            if len(lineTokenized) > 0:\n",
    "                lineTokenized.insert(0,i) ##almacena el numero de linea al que pertenece en la cabeza de la lista\n",
    "                tokens.append(lineTokenized)\n",
    "    \n",
    "        for linea in tokens:\n",
    "            numpalabra=0\n",
    "            numlinea=linea[0]\n",
    "            for palabra in linea:\n",
    "                if type(palabra) is not int:\n",
    "                    if palabra not in stopWords and palabra not in stopWordsEngl:\n",
    "                        if palabra not in headIndexer:\n",
    "                            match=Match(numlinea,[numpalabra])\n",
    "                            headIndexer.update({palabra:{numDoc:[1,match]}})## psible bug\n",
    "                        else:\n",
    "                            #si el documento no esta en elindexador\n",
    "                            dicDocs= headIndexer.get(palabra)\n",
    "                            if numDoc not in dicDocs:\n",
    "                                match=Match(numlinea,[numpalabra])\n",
    "                                dicDocs.update({numDoc:[1,match]})\n",
    "                            #si el documento ya esta en el indexador\n",
    "                            else:\n",
    "                                headIndexer.get(palabra).get(numDoc)[0]+=1 ##actualiza a cantidad de ocurrencias\n",
    "                                matchAnterior=headIndexer.get(palabra).get(numDoc)[-1]\n",
    "                                if matchAnterior.getLinea() == numlinea:\n",
    "                                    matchAnterior.addOcurrencias([numpalabra])\n",
    "                                else:\n",
    "                                    match=Match(numlinea,[numpalabra])\n",
    "                                    headIndexer.get(palabra).get(numDoc).append(match)\n",
    "                    numpalabra+=1\n",
    "            numlinea+=1\n",
    "        numDoc+=1\n",
    "    return headIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rutina para indexador\n",
    "# recibe una lista de nombres de documentos \n",
    "#retorna un diccionario (la estructura del indexador)\n",
    "headIndexer={}\n",
    "numeroPalabrasPorDoc=[]\n",
    "def makeIndex2(docs:list):\n",
    "    numDoc=0\n",
    "    for x in docs:\n",
    "        numeroPalabrasPorDoc.append([])\n",
    "        tokens=[]\n",
    "        doc=open(x,encoding='utf8')\n",
    "        data=doc.readlines()\n",
    "        ##para cada linea en el documento\n",
    "        for i in range(len(data)):\n",
    "            data[i]=normal(data[i])\n",
    "            lineTokenized=word_tokenize(data[i])\n",
    "            numeroPalabrasPorDoc[numDoc].append(len(lineTokenized))\n",
    "            if len(lineTokenized) > 0:\n",
    "                lineTokenized.insert(0,i) ##almacena el numero de linea al que pertenece en la cabeza de la lista\n",
    "                tokens.append(lineTokenized)\n",
    "    \n",
    "        for linea in tokens:\n",
    "            numpalabra=0\n",
    "            numlinea=linea[0]\n",
    "            for palabra in linea:\n",
    "                if type(palabra) is not int:\n",
    "                    if palabra not in stopWords and palabra not in stopWordsEngl:\n",
    "                        if palabra not in headIndexer:\n",
    "                            match=Match(numlinea,[numpalabra]).getMatch()\n",
    "                            headIndexer.update({palabra:{numDoc:[1,match]}})## psible bug\n",
    "                        else:\n",
    "                            #si el documento no esta en elindexador\n",
    "                            dicDocs= headIndexer.get(palabra)\n",
    "                            if numDoc not in dicDocs:\n",
    "                                match=Match([numlinea,numpalabra]).getMatch()\n",
    "                                print(match)\n",
    "                                dicDocs.update({numDoc:[1,match]})\n",
    "                            #si el documento ya esta en el indexador\n",
    "                            else:\n",
    "                                headIndexer.get(palabra).get(numDoc)[0]+=1 ##actualiza la cantidad de ocurrencias\n",
    "                                matchAnterior=headIndexer.get(palabra).get(numDoc)[-1]\n",
    "                                extractor=Match(matchAnterior)\n",
    "                                if extractor.getLinea(matchAnterior) == numlinea:\n",
    "                                    extractor.addOcurrencias(matchAnterior,[numpalabra])\n",
    "                                else:\n",
    "                                    match=Match(numlinea,[numpalabra])\n",
    "                                    headIndexer.get(palabra).get(numDoc).append(match)\n",
    "                    numpalabra+=1\n",
    "            numlinea+=1\n",
    "        numDoc+=1\n",
    "    return headIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'makeIndex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-a83aa9e7ae0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"server.py\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mindexado\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmakeIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mindexado\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'makeIndex' is not defined"
     ]
    }
   ],
   "source": [
    "txt=[\"server.py\"]\n",
    "indexado=makeIndex(txt)\n",
    "indexado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para buscar en el indexador\n",
    "    # abrir todos los documentos y guaradar todos sus apuntadores en una lista\n",
    "    # leer cada documento y en un array de lineas y alamacenarlos en una lista (hbuffer)\n",
    "    #si la palabra esta en el indexador\n",
    "        #recibir el diccionario de documentos correspondiente a la palabra\n",
    "        #recorrer cada elemento en el diccionario\n",
    "            #recorrer cada valor en la lista del elemento del diccionario\n",
    "                #si el valor en la lista es un entero(el entero es el numero de incidencias)\n",
    "                    #imprimir el numero ocurrencias y el nombre del documento\n",
    "                #sino\n",
    "                    #imprimir la lista de ocurrencias del primer match\n",
    "                    #imprimir la linea del documento original almacenada en (hbuffer)\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbuffer=[]\n",
    "for x in range(len(txt)):\n",
    "    hbuffer.append(None)\n",
    "#funcion que recibe la palabra y el indexador e imprime los rsultados de la busqueda\n",
    "def searchIndex(word,index):\n",
    "    if word in index:\n",
    "        dicDoc=index.get(word)\n",
    "        for doc in dicDoc:\n",
    "            #buffer.insert(doc,open(txt[doc],encoding='utf8'))\n",
    "            #print(buffer)\n",
    "            hbuffer[doc]=open(txt[doc],encoding='utf8').readlines()\n",
    "            for value in dicDoc[doc]:\n",
    "                if type(value) is int:\n",
    "                    print(\"{} ocurrencias en {}\".format(value,txt[doc]))\n",
    "                else:\n",
    "                    lst=list(map(lambda x: x+1,value.getOcurrencias())) #le suma uno a cada elemento de las ocurrencias\n",
    "                    print(\"\\tEn linea {} \\n\\t\\tpalabra {}\".format(value.getLinea()+1,lst))\n",
    "                    print(\"\\n\\t{}\".format(hbuffer[doc][value.getLinea()]))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexado=makeIndex(['textDocs/likeAPrayer.txt','textDocs/sencillosMasVendidosDelMundo.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ocurrencias en server.py\n",
      "\tEn linea 22 \n",
      "\t\tpalabra [3]\n",
      "\n",
      "\tif __name__=='__main__':\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searchIndex(\"main\",indexado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, <__main__.Match at 0xb32bfd0>]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexado.get(\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'filesCSV',\n",
       " 'filesPDF',\n",
       " 'indexer.py',\n",
       " 'paraPruebas.ipynb',\n",
       " 'readme.md',\n",
       " 'server.py',\n",
       " 'static',\n",
       " 'templates',\n",
       " 'textDocs',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filesCSV/COM-CUATRI-PRIMAVERA2020.csv',\n",
       " 'filesCSV/COM-SEM-PRIMAVERA2020.csv',\n",
       " 'filesCSV/ICC-CUIATRI-PRIMAVERA2020.csv',\n",
       " 'filesCSV/ICC-SEM-PRIMAVERA2020.csv',\n",
       " 'filesCSV/ITI-CUATRI-PRIMAVERA2020.csv',\n",
       " 'filesCSV/ITI-SEM-PRIMAVERA2020.csv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x : \"filesCSV/\"+x,nn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
